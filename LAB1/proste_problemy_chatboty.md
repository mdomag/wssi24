Proste problemy, chatboty

Zadanie 1

Zadania związane z językiem naturalnym, takie jak streszczanie tekstu, tłumaczenie tekstu, klasyfikacja tekstu do kategorii tematycznych uważam za wymagające ludzkiej inteligencji. Co prawda sztuczna inteligencja szczególnie w ostatnich czasach (chatboty pokroju ChatGPT) pokazuje znaczący postęp w tej dziedzinie, wypełniając polecenia na poziomie wystarczającym do usatysfakcjonowania niezbyt wygórowanych oczekiwań. Nie sądzę jednak, że postęp ten pozostanie liniowy z powodu skomplikowanej natury języka – wyuczenia leksykonu, syntaktyki, przypadków użycia, pozostaje jeszcze kwestia innowacyjności językowej wymagającej wyobraźni oraz emocjonalności. Tłumaczenie i streszczanie tekstów trudniejszych pod względem zawiłości języka zdecydowanie wymaga wkładu człowieka, szczególnie przy tekstach wymagających tzw. czytania między wierszami, który to proces nie zawsze da się wyjaśnić, a co za tym idzie przełożyć na etapy zrozumiałe dla SI. Szczególnie tłumaczenia szeroko pojętej sztuki – od książek po filmy, wymaga nie tylko znajomości języka, innych utworów autora, kontekstu powstania, ale i przede wszystkim dużego wkładu twórczego. Również teksty naukowe nie są łatwym terenem dla SI, wymagają one wiedzy eksperckiej i często są to teksty wysokiej wagi – błędy mogą prowadzić do poważnych konsekwencji (dezinformacji czy dyskredytacji badań). Streszczanie tekstu oraz klasyfikacja do kategorii tematycznych często polega na algorytmie wyszukującym słowa klucze, może być to skuteczna strategia dla prostego materiału źródłowego o szablonowym stylu pisarskim, jednak problemy pojawiają się przy materiale odbiegającym od standardu lub poruszającym niespotykany temat. Z podobnych powodów jak przy tłumaczeniu uważam, że proces ten wymaga inteligencji ludzkiej. 

Programowanie według mnie wymaga inteligencji ludzkiej. Rozwiązywanie schematycznych problemów raczej da się zautomatyzować, jednak tych nietrywialnych już niezbyt.  Dzieje się tak, gdyż oprócz wyuczenia się schematów niezbędna jest tu również kreatywność i innowacyjność. Pisanie dobrego kodu opiera się na dogłębnym zrozumieniu problemu i doświadczeniu. Trzeba również pamiętać, że często sama zdolność tworzenia kodu nie wystarcza – należy dodatkowo umieć go wyjaśnić. Podobnymi argumentami poparłabym tezę, że do testowania kodu również niezbędny jest wkład ludzki. W szczególności przydatne jest tu nieszablonowe myślenie pozwalające na testowanie przypadków brzegowych. 
	Uważam więc, że programowania wymaga co najmniej aktywnego nadzoru ludzkiego, w tym testera. Oczywiście wypowiedź ta nacechowana jest stronniczością, ponieważ zależy od tego moja przyszłość w zawodzie. ˙ᵕ˙

Komponowanie muzyki uważam za wymagające wkładu ludzkiego, szczególnie gdy rozważamy je jako sztukę. Tak jak w powyższych przykładach wymagana jest tu kreatywność i emocjonalność. 

Jazda samochodem z autopilotem nadal wymaga uwagi i czasem interwencji ze strony człowieka. W skrócie autopilot nie jest niezawodny, w szczególności kiedy zestawiony z nieobliczalnością innych użytkowników drogi oraz pogody. Uważam więc, że jest tutaj niezbędny nadzór ze strony kierowcy. 

Zadanie 2

  Za mieszczące się w zakresie sztucznej inteligencji uznałabym: odpowiadanie na proste zadania w języku naturalnym, układanie rozkładu jazdy, rozwiązywanie układów równań liniowych, symboliczne obliczanie pochodnych, symboliczne całkowanie. Nie licząc pierwszego przykładu, są to zadania, które operują na językach sztucznych i które można zautomatyzować, dysponując wystarczającą bazą danych i zasadami działania. Rozwiązywanie tych problemów jest raczej schematyczne. Pierwszy przykład natomiast operuje na języku naturalnym, więc z pewnością przysparza więcej problemów, jednak z racji, że mowa tu o „prostych” pytaniach, myślę, że może on znaleźć się na tej liście. Inne zadania oparte na języku naturalnym – streszczanie, tłumaczenia i klasyfikacja do kategorii tematycznych, mieszczą się w tym zakresie, gdy mowa o działaniu na prostych tekstach. 

Zadanie 3

Odpowiadanie na proste pytania klientów w zarówno internetowej, jak i telefonicznej infolinii jest obecnie skutecznie imitowane. Wiele firm wprowadza automatyzację obsługi klientów właśnie w takiej formie. Częściej stosowana jest forma w internetowej infolinii, ale przykładem wykorzystującym infolinię telefoniczną jest, np. asystent głosowy Max należący do firmy Orange. Lista sztucznych systemów imitujących rozmowy towarzyskie jest długa, ich skuteczność jednak często pozostawia wiele do życzenia. Przystosowują się one do użytkownika, myślę więc, że można je naprowadzić na dyskusje polityczne i naukowe, jednak wartość merytoryczna takiej wymiany „opinii” nie jest zbyt wysoka. 

Zadanie 4

1) Bot udający człowieka przygotowany jest do odpowiedzi na wszelakie pytania, jest próbą symulacji rozmowy towarzyskiej, gdzie bot asystent przygotowany jest na odpowiadania na pytania tyczące się tylko ściśle określonego tematu, jego zadaniem jest pomoc w sprawniejszym uzyskaniu informacji w danym zakresie.

2) Wykorzystałam do tego zadania ChatGPT (chatbot do wszelakich celów) i Phind (chatbot zaprojektowany do pomocy programistom).

3) ChatGPT generuje od razu krótkie żarty, łatwo dostosowuje żarty do podanych kategorii. Phind nie rozumie od razu polecenia, ale po dalszym nakierowaniu udało mu się wyprodukować kilka absurdalnie długich żartów na temat informatyków*.   
ChatGPT jest w stanie przytoczyć moje wcześniejsze zapytania oraz cytaty sławnych osób. Phind nie potrafi przytoczyć mojego zapytania, jedynie je opisać, nie przechowuje on historii rozmów. Nie ma problemu z przytaczaniem cytatów znanych osób. 
ChatGPT trzyma się słów kluczowych, szczególnie, gdy zadaje mu się pytania pozornie wymagające wyobraźni, podobnie Phind.
ChatGPT odpowiada na wszystkie proste pytania po kolei. Tak samo Phind. Nie trudno jednak wpaść w błędne koło z chatbotem, często po informacji, że jego odpowiedź jest błędna, bot przeprasza ale generuje to samo rozwiązanie. 
Obydwa chatboty radzą sobie zazwyczaj dobrze przy nawiązywaniu do moich poprzednich zapytań, wnioskują one bowiem na podstawie kontekstu rozmowy. Potrafią one czasem zbytnio trzymać się kontekstu i proponować jako poprawne rozwiązanie podane przeze mnie wcześniej błędne odpowiedzi.
Obydwa chatboty wymijają się od odpowiedzi przy niebezpiecznych tematach. Dają sobie radę z częstą zmianą tematu rozmowy i nie mają za dużych problemów z utrzymywaniem wątków. 
Wybrane przeze mnie chatboty są dość podobne. Widać jednak, że Phind został stworzony jako asystent w konkretnej dziedzinie, jest ograniczony przy wychodzeniu poza temat programowania. ChatGpt ma szersze zastosowania, spełnia się więc lepiej w rozmowie. 

4)  Wymiana wypowiedzi między botami zazwyczaj kończy się co raz to milszym proponowaniem pomocy. ChatGPT poinformowany o tym, że będzie „rozmawiał” z Phindem jedynie zadaje mu pytanie w obszarze działania Phinda – informatycznym i dziękuje za odpowiedzi. 

5) Ciężko było mi zdenerwować któregokolwiek bota, prędzej to one zdenerwowały mnie (swoją inkompetencją). Zostały one stworzone jako produkty komercyjne, nic dziwnego więc, że zostały one ograniczone pod tym względem – przy obrażeniu bota, ten jedynie przeprasza i pyta jak inaczej może pomóc.

*Treść żartu:
![Zrzut ekranu 2024-03-26 201835](https://github.com/mdomag/wssi24/assets/126866195/6113ca1e-ee28-453b-a178-4430329dff2c)
